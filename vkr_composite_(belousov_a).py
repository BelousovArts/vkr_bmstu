# -*- coding: utf-8 -*-
"""VKR Composite (Belousov A).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4jv9UZkBG9RX0n9v3GbvanT-ix5UIsB
"""

# Commented out IPython magic to ensure Python compatibility.
# Импорт библиотек
import numpy as np  #работа с массивами
import pandas as pd #работа с данными (таблицами)
import matplotlib.pyplot as plt #визуализация
import seaborn as sns #визуализация в статистике

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
import tensorflow as tf

# %matplotlib inline

df = pd.read_csv('/content/X_bp.csv', delimiter=';',index_col=0)
df.head(5)

df.describe()

"""**Основная концепция:**
Данные в столбцах перемешены в случайном порядке не зависимо друг от друга.
Требуется сортировка даннных.

Сортировку будем проводить исходя из физики, механики и логики

Отсортируем по столбцу "Соотношение матрица-наполнитель"
"""

df_sort = df.sort_values('Соотношение матрица-наполнитель').reset_index(drop=True)
df_sort.head(5)

sns.set(style = "darkgrid")
sns.set(font_scale=0.6)
sns.pairplot(df_sort)

sns.set(font_scale=1)
df_corr = df.corr()
plt.figure(figsize=(10,8))
sns.heatmap(data=df_corr, vmin=-1, vmax=1, annot=True, cmap='coolwarm')
plt.show()

"""Исходя из физики, механики и логики должны соблюдаться условия:

- чем больше соотношение матрица/наполнитель, тем больше в композите связующего, соответственно и больше потребление смолы. (условие не наблюдается)

- чем больше соотношение матрица/наполнитель, тем меньше плотность. В качестве связующего выступает эпоксидная смола (1250 кг/м3), а в качестве наполнителя больше подходит высокомодульное стекловолокно (2660 кг/м3). Другими словами, чем больше доля связующего с плотностью меньше наполнителя, тем плотность композита будет меньше. (условие не наблюдается)

- чем больше соотношение матрица/наполнитель, тем меньше Модуль упругости, модуль упругости на растяжение и прочность на растяжение (при условии растяжения вдоль волокон). Модуль упругости эпоксидной смолы 3-4.5 ГПа, высокомодульное стекло 86 ГПа. В столбце Модуль упругости некоректные значения: 1900ГПа нереально высокое значение (у стали 200ГПа для сравнения), возможно неправильные единицы измерения или что-то другое. (условие не наблюдается)

- чем больше плотность, тем больше и поверхностная плотность. (условие не наблюдается)

- с количеством отвердителя и содержанием эпоксидных групп менее понятно, но можно предположить, что чем больше потребление смолы, тем больше количество отвердителя и содержание эпоксидных групп.

- по температуре вспышке можно предположить, что чем больше смолы, тем ниже температура вспышки. (эпоксидная смола температура вспышки примерно 150 градусов, стекловолокно не меньше 1200 градусов)

Соответственно из вышеизложенных условий, делаем вывод, что данные в переменных случайным образом были перемешены независимо друг от друга.

Произведем преобразования:

- Соотношение матрица/наполнитель: сортировка по возврастанию

- Плотность: сортировка по убыванию

- Модуль упругости: удалим столбец в связи некоректными данными

- Количество отвердителя: сортировка по возврастанию

- Содержание эпоксидных групп: сортировка по возврастанию

- Температура вспышки: сортировка по убыванию

- Поверхностная плотность: сортировка по убыванию

- Модуль упругости при растяжении: сортировка по убыванию

- Прочность при растяжении: сортировка по убыванию

- Потребление смолы: сортировка по возврастанию
"""

# удаляем столбец: модуль упругости. ГПа
df_sort = df_sort.drop(columns=['модуль упругости. ГПа'])
df_sort.head(5)

# независимая сортировка
df_sort[['Плотность. кг/м3']] = df_sort[['Плотность. кг/м3']].sort_values(by ='Плотность. кг/м3',ascending=[False]).reset_index(drop=True)
df_sort[['Количество отвердителя. м.%']] = df_sort[['Количество отвердителя. м.%']].sort_values(by ='Количество отвердителя. м.%').reset_index(drop=True)
df_sort[['Содержание эпоксидных групп.%_2']] = df_sort[['Содержание эпоксидных групп.%_2']].sort_values(by ='Содержание эпоксидных групп.%_2').reset_index(drop=True)
df_sort[['Температура вспышки. С_2']] = df_sort[['Температура вспышки. С_2']].sort_values(by ='Температура вспышки. С_2').reset_index(drop=True)
df_sort[['Поверхностная плотность. г/м2']] = df_sort[['Поверхностная плотность. г/м2']].sort_values(by ='Поверхностная плотность. г/м2',ascending=[False]).reset_index(drop=True)
df_sort[['Модуль упругости при растяжении. ГПа']] = df_sort[['Модуль упругости при растяжении. ГПа']].sort_values(by ='Модуль упругости при растяжении. ГПа',ascending=[False]).reset_index(drop=True)
df_sort[['Прочность при растяжении. МПа']] = df_sort[['Прочность при растяжении. МПа']].sort_values(by ='Прочность при растяжении. МПа',ascending=[False]).reset_index(drop=True)
df_sort[['Потребление смолы. г/м2']] = df_sort[['Потребление смолы. г/м2']].sort_values(by ='Потребление смолы. г/м2').reset_index(drop=True)
df_sort.head()

"""Можно проверить по теоритической формуле расчета плотности композита, исходя из объемных долей матрицы и наполнителя.

В первой строке наименьшее содержание смолы и соответственно наибольшая плотность.

Формула для расчета:

**Ro_comp = Ro_n * nu_n + Ro_m * nu_m**

Ro_comp - плотность композита

Ro_n - плотность наполнителя

Ro_m - плотность матрицы

nu_n - объемная доля наполнителя

nu_m - объемная доля матрицы

Для первой строки отсортированного датасета Соотношение матрица/наполнитель или **nu_m/nu_n = 0.389403**,

при этом **nu_m + nu_n = 1**

Соответственно **nu_m = 0.28027**, а **nu_n = 0.71973**

Тогда плотность композита **Ro_comp = 2660  * 0.71973 + 1250 * 0.28027 = 2264,8193**

При табличном значении **2207.7734**, вполне похоже на правду.
"""

sns.set(style = "darkgrid")
sns.set(font_scale=0.6)
sns.pairplot(df_sort)

sns.set(font_scale=1)
df_sort_corr = df_sort.corr()
plt.figure(figsize=(10,8))
sns.heatmap(data=df_sort_corr, vmin=-1, vmax=1, annot=True, cmap='coolwarm')
plt.show()

"""Соответственно появилась явная корреляция)

С этими данными можно работать, удалять выбросы, нормализовывать, строить регрессионные модели и тд.

Далее для примера построил нейронную сеть для прогнозирования модуля упругости при растяжении.

На входе 4 параметра: **'Соотношение матрица-наполнитель', 'Количество отвердителя. м.%', 'Температура вспышки. С_2', 'Потребление смолы. г/м2'**

На выходе 1 параметр: **'Модуль упругости при растяжении. ГПа'**
"""

#нормализация (-1, 1)
from sklearn.preprocessing import MinMaxScaler
minmax_scaler_X = MinMaxScaler(feature_range=(-1, 1))
minmax_scaler_y = MinMaxScaler(feature_range=(-1, 1))
df_sort_nrm = pd.DataFrame()
df_sort_nrm[['Соотношение матрица-наполнитель', 'Количество отвердителя. м.%', 'Температура вспышки. С_2', 'Потребление смолы. г/м2']] = minmax_scaler_X.fit_transform(df_sort[['Соотношение матрица-наполнитель', 'Количество отвердителя. м.%', 'Температура вспышки. С_2', 'Потребление смолы. г/м2']])
df_sort_nrm[['Модуль упругости при растяжении. ГПа']] = minmax_scaler_y.fit_transform(df_sort[['Модуль упругости при растяжении. ГПа']])
df_sort_nrm.describe()

X = np.array(df_sort_nrm[['Соотношение матрица-наполнитель', 'Количество отвердителя. м.%', 'Температура вспышки. С_2', 'Потребление смолы. г/м2']]) # входные данные
y = np.array(df_sort_nrm[['Модуль упругости при растяжении. ГПа']])  # выходные данные


# разделение данных на тренировочную и тестовую выборку
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True, random_state=42)
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

# архитектура нейронной сети
model = Sequential()
model.add(Dense(4, input_dim = X_train.shape[1], activation='linear')) # входной слой
model.add(Dense(32, activation= 'relu'))
model.add(Dense(16, activation= 'relu'))
model.add(Dense(1, activation= 'linear'))

callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)
model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.MeanAbsoluteError()]) # компиляция
model.summary()

# Обучение нейронной сети
history = model.fit(X_train, y_train, epochs = 100, validation_data = (X_test, y_test), callbacks=[callback])
print(history.history.keys())

plt.plot(history.history['loss'], label = 'Ошибка на обучающей выборке')
plt.plot(history.history['val_loss'], label = 'Ошибка на тестовой выборке')
plt.xlabel('Эпохи')
plt.ylabel('Значение ошибки MSE')
plt.legend()
plt.show()

res = model.predict(X)
res = minmax_scaler_y.inverse_transform(res)

plt.figure(figsize=(15,10))
plt.scatter(df_sort['Соотношение матрица-наполнитель'],df_sort['Модуль упругости при растяжении. ГПа'], linewidths=0.1, label = 'Эксперементальные значения')
plt.plot(df_sort['Соотношение матрица-наполнитель'], res, 'r', linewidth=2, label = 'Прогноз')
plt.xlabel('Соотношение матрица-наполнитель')
plt.ylabel('Модуль упругости при растяжении. ГПа')
plt.legend()
plt.show()